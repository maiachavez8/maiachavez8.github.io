[
  {
    "objectID": "miniproject/maps/index.html",
    "href": "miniproject/maps/index.html",
    "title": "Maps: US States Data",
    "section": "",
    "text": "The data set I used has information on all death penalties that were carried out since 1976, and information about the people executed. I thought it might be interesting to see if there are any racial biases in who is sentenced to death. I made a new data set from the one below using the variables Race and State.\n\nexecution\n\n# A tibble: 1,583 × 27\n   `Foreign National` Number of White Male V…¹ Juvenile `First Name` `Last Name`\n   &lt;chr&gt;                                 &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt;      \n 1 No                                        1 no       Gary         Gilmore    \n 2 No                                        1 no       John         Spenkelink \n 3 No                                        1 no       Jesse        Bishop     \n 4 No                                        2 no       Steven       Judy       \n 5 No                                        1 no       Frank        Coppola    \n 6 No                                        1 no       Charlie      Brooks     \n 7 No                                        1 no       John         Evans      \n 8 No                                        0 no       Jimmy        Gray       \n 9 No                                        1 no       Robert       Sullivan   \n10 No                                        0 no       Robert       Williams   \n# ℹ 1,573 more rows\n# ℹ abbreviated name: ¹​`Number of White Male Victims`\n# ℹ 22 more variables: `Middle Name(s)` &lt;chr&gt;, Suffix &lt;chr&gt;, Race &lt;chr&gt;,\n#   Sex &lt;chr&gt;, Region &lt;chr&gt;, Country &lt;chr&gt;, State &lt;chr&gt;,\n#   `Execution Date` &lt;chr&gt;, `Number of Victims` &lt;dbl&gt;,\n#   `Number of Black Male Victims` &lt;dbl&gt;,\n#   `Number of Latino Male Victims` &lt;dbl&gt;, …\n\n\nI collapsed Race into two values: white and person of color. Then using the counts of each race executed by state I was able to pivot the data set so each state only had one row with columns white and person of color. Then using summarize, I found the proportion of people of color executed to total people executed for each state.\n\nstate_execution &lt;- execution |&gt;\n  mutate(race= \n           fct_collapse(Race,poc= c(\"American Indian or Alaska Native\", \"Asian\", \"Latinx\", \"Other Race\", \"Black\"\n), white= \"White\")) |&gt;\n  group_by(State) |&gt;\n  count(race) |&gt;\n  pivot_wider(names_from= race, values_from= n, \n              values_fill= 0) |&gt;\n  summarize(prop_poc_ex= poc/(poc+white)) |&gt;\n  mutate(State = str_to_lower(State))\n\nstate_execution\n\n# A tibble: 35 × 2\n   State       prop_poc_ex\n   &lt;chr&gt;             &lt;dbl&gt;\n 1 alabama           0.438\n 2 arizona           0.25 \n 3 arkansas          0.355\n 4 california        0.385\n 5 colorado          0    \n 6 connecticut       0    \n 7 delaware          0.5  \n 8 federal           0.562\n 9 florida           0.362\n10 georgia           0.368\n# ℹ 25 more rows\n\n\nNext I made a plot to visually these proportions across states.\n\nstate_execution |&gt;\n  right_join(us_states, by = c(\"State\" = \"region\")) |&gt;\n  ggplot(mapping = aes(x = long, y = lat,\n                          group = group)) + \n  geom_polygon(aes(fill = prop_poc_ex), color = \"black\") +\n  labs(fill= \"Percent Executions who were POC\", title= \"How many people sentenced to death in prison are people of color?\", subtitle= \"Taken from all executions carried out since 1976\", caption= \"Data: https://deathpenaltyinfo.org/database/executions\") +\n  coord_map() + \n  theme_void() +\n  scale_fill_viridis(direction=-1) \n\n\n\n\nThere are some limitations to the data, as there was no data on 15 states, shown in grey above. Also some of the states had only a few people executed which could skew percentages. Also in places like California and Texas, the percentage of people of color is higher, so the amount of people of color executed would naturally be higher. There aren’t any obvious racial biases, however some states do have a higher percentage of people of color executed. For example, Florida has a 40% poc execution rate while their overall person of color population is around 30%, and Florida has a lot of values in the data set. I might be interesting to do more in depth of analysis of this data to truly determine any biases."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Maia Chavez",
    "section": "",
    "text": "Chemistry Major with Statitics and Data Science Concentration  @ St. Olaf College\n\n\n\n\nGet in Touch\nEmail: chavez@stolaf.edu\nOffice: Newhall 247A\nAddress: 1520 St. Olaf Ave, Northfield, MN 55057\nPhone: 952-460-0951"
  },
  {
    "objectID": "miniproject2.html",
    "href": "miniproject2.html",
    "title": "Mini Project 2",
    "section": "",
    "text": "Casein is the main protein present in cow’s milk. It is good for building muscle and growth, as cow babies grow up on this protein. It has been shown to have many benefits for humans, especially for bodybuilders and people in recovery from injury. It is likely to have good growth benefits for other animals as well. One study, looked at growth rates for chicks who were fed different types of feed, one of which was supplemented with casein. By comparing weights of the chicks on casein vs. other feed, we can see the effect casein has on a chicks growth.\n\n\n\nNull hypothesis: Feeding your chicks casein will have no affect on their weight compared to other types of feed\nAlternative hypothesis: Feeding your chicks casein will have an affect on their weight.\nSpecifically, I think casein will make chicks heavier on average.\n\n\n\nI am starting out by using the chickwts data set described above. I am making a tibble for me to use in testing my hypothesis. For the purposes of this analysis I am classifying the chick weights as high if they are in the top 50% of weights and low if they are in the bottom 50% of weights. I am also lumping the other types of feed into one category to be my “control”. Essentially this will compare the weights of the chickens on casein feed to the weights of the chickens on other feeds.\n\ncasein &lt;- chickwts |&gt;\n  mutate(feed= fct_collapse(feed, other = c(\"linseed\", \"sunflower\", \"soybean\", \"horsebean\", \"meatmeal\")))\n\ncasein$weight2 &lt;- ifelse(casein$weight &gt; 265, 'HIGH', 'LOW')\ncasein_final &lt;- tibble(casein |&gt;\n  select(feed, weight2) |&gt;\n  mutate(weight = as.factor(weight2)) |&gt;\n  select(-weight2))\n\ncasein_final \n\n# A tibble: 71 × 2\n   feed  weight\n   &lt;fct&gt; &lt;fct&gt; \n 1 other LOW   \n 2 other LOW   \n 3 other LOW   \n 4 other LOW   \n 5 other LOW   \n 6 other LOW   \n 7 other LOW   \n 8 other LOW   \n 9 other LOW   \n10 other LOW   \n# ℹ 61 more rows\n\n\nNote: The variable “feed” has two levels, other and casein, while the variable “weight” has two levels, high and low.\nNext, I can start the analysis…\n\n\n\nFirst, I wrote a code to calculate the observed difference between the proportion of higher weight chicks between groups for the treatment (casein) and control (other) groups.\n\ncasein_summary &lt;- casein_final |&gt;\n group_by(feed) |&gt;\n  summarise(prop_high = mean (weight==\"HIGH\"))\nobserved_diff_cas &lt;- casein_summary [[2]][1] -casein_summary[[2]][2]\ncasein_summary\n\n# A tibble: 2 × 2\n  feed   prop_high\n  &lt;fct&gt;      &lt;dbl&gt;\n1 casein     0.75 \n2 other      0.390\n\nobserved_diff_cas \n\n[1] 0.3601695\n\n\nIt is also interesting to note that we can turn the above code into a function. For simple randomized studies, specifically those with a treatment variable consisting of two levels and a categorical two level outcome, we can create a function that calculates the observed difference and shows the observed proportions of the outcome.\n\ncreate_summary_obsdiff &lt;- function(data, treatment, outcome, prop) {\n  sum &lt;- data |&gt;\n group_by({{treatment}}) |&gt;\n  summarise(prop_yes = mean ({{outcome}}== prop))\n  observed_diff &lt;- sum [[2]][1] -sum[[2]][2]\nprint(sum)\nobserved_diff \n  } \n\ncreate_summary_obsdiff(casein_final, feed, weight, \"HIGH\")\n\n# A tibble: 2 × 2\n  feed   prop_yes\n  &lt;fct&gt;     &lt;dbl&gt;\n1 casein    0.75 \n2 other     0.390\n\n\n[1] 0.3601695\n\n\nWe could do this with the dolphin data set that we were working with in class where the data would be dolphin data, the treatment would be treatment with levels Dolphin and Control, the outcome would be improve with levels yes and no, and the prop would be “Yes”. Outcome refers to the response variable you will be examining and prop refers to what you will be calculating the proportion of within that outcome. Usually we look at positive improvements or the presence of something, so I named this variable prop_yes.\nExample with Dolphin Data\n\ndolphin_data &lt;- tibble(treatment = rep(c(\"Dolphin\", \"Control\"), each = 15),\n                       improve = c(rep(\"Yes\", 10), rep(\"No\", 5), \n                                   rep(\"Yes\", 3), rep(\"No\", 12)))\n\ncreate_summary_obsdiff(dolphin_data, treatment, improve, \"Yes\")\n\n# A tibble: 2 × 2\n  treatment prop_yes\n  &lt;chr&gt;        &lt;dbl&gt;\n1 Control      0.2  \n2 Dolphin      0.667\n\n\n[1] -0.4666667\n\n\n\n\n\nNext, we will create a null world that shuffles the feed or treatment among the chicks. We can calculate the simulated difference, which is the difference in proportion of higher weight chicks if there was no dependence on feed.\n\nsimulated_diff_cas &lt;- vector(\"double\", 1000)\nfor(i in 1:1000) {\n  casein_summary1 &lt;- casein_final |&gt;\n  mutate(shuffled_treatment = sample(feed)) |&gt;\n  group_by(shuffled_treatment) |&gt;\n  summarize(prop_yes = mean (weight==\"HIGH\"))\nsimulated_diff_cas[[i]] &lt;- casein_summary1[[2]][1]-casein_summary1[[2]][2]\n}\n\n\n\n\nFinally we can use these simulated differences to calculate how rare getting our observed difference would be.\n\nnull_world_cas &lt;- tibble(simulated_diff_cas = simulated_diff_cas)\nggplot(null_world_cas, aes(x=simulated_diff_cas)) +\n  geom_histogram(bins= 25, fill= \"darkseagreen1\")+\n  geom_vline(xintercept= observed_diff_cas, color= \"hotpink\") +\n  theme_classic() + \n  labs(x= \"Simulated Difference Between Feed types\", y= \"Count\",\n       title= \"Simulation of the Difference in the Proportion of Higher Weight Chicks \nfed with Casein feed and Other Types of Feed in the Null World\", subtitle= \"With a Line Representing the the Observed Difference\", \ncaption=\"Source: Anonymous (1948) Biometrika, 35, 214\")\n\n\n\n\nLooking at the above plot, we can see our simulated null world approximately follows the normal curve, with the mean around zero. This would make sense if there is no difference in types of feed in this simulation because the average weight should be about the same for both groups. Assuming the casein feed has no affect on chick weights, the bulk of the simulated differences lie between -0.25 and 0.25. The pink line represents our observed difference, which is possible to obtain if casein has no affect on chick weight, but it is more unlikely.\n\np_value &lt;- sum(simulated_diff_cas&gt;=observed_diff_cas)/1000\np_value\n\n[1] 0.027\n\n\nWe can also calculate the p-value which is shown above. The p-value represents the chance that we would get an observed difference that is equal to or above the difference that we got. Because our p-value is less than 0.05, we can reject the null hypothesis that casein feed has no effect on chick weights compared to other types of feed.\n\n\n\nThe p-value can also be analyzed by a two sided test, instead of a one sided test. This would take into account the probability of getting the negative of our observed difference and lower. This would raise our p-value. It would be interesting to study chicks with a more consistent control group like the most common type of feed, instead of random feeds lumped together. It would also be interesting to pair this with an analysis of average chick weights at certain points in life in order to get a better understanding of a higher and lower weight chick. The data would also be more accurate with a larger sample size."
  },
  {
    "objectID": "miniproject2.html#background",
    "href": "miniproject2.html#background",
    "title": "Mini Project 2",
    "section": "",
    "text": "Casein is the main protein present in cow’s milk. It is good for building muscle and growth, as cow babies grow up on this protein. It has been shown to have many benefits for humans, especially for bodybuilders and people in recovery from injury. It is likely to have good growth benefits for other animals as well. One study, looked at growth rates for chicks who were fed different types of feed, one of which was supplemented with casein. By comparing weights of the chicks on casein vs. other feed, we can see the effect casein has on a chicks growth."
  },
  {
    "objectID": "miniproject2.html#hypothesis",
    "href": "miniproject2.html#hypothesis",
    "title": "Mini Project 2",
    "section": "",
    "text": "Null hypothesis: Feeding your chicks casein will have no affect on their weight compared to other types of feed\nAlternative hypothesis: Feeding your chicks casein will have an affect on their weight.\nSpecifically, I think casein will make chicks heavier on average."
  },
  {
    "objectID": "miniproject2.html#creating-the-dataset",
    "href": "miniproject2.html#creating-the-dataset",
    "title": "Mini Project 2",
    "section": "",
    "text": "I am starting out by using the chickwts data set described above. I am making a tibble for me to use in testing my hypothesis. For the purposes of this analysis I am classifying the chick weights as high if they are in the top 50% of weights and low if they are in the bottom 50% of weights. I am also lumping the other types of feed into one category to be my “control”. Essentially this will compare the weights of the chickens on casein feed to the weights of the chickens on other feeds.\n\ncasein &lt;- chickwts |&gt;\n  mutate(feed= fct_collapse(feed, other = c(\"linseed\", \"sunflower\", \"soybean\", \"horsebean\", \"meatmeal\")))\n\ncasein$weight2 &lt;- ifelse(casein$weight &gt; 265, 'HIGH', 'LOW')\ncasein_final &lt;- tibble(casein |&gt;\n  select(feed, weight2) |&gt;\n  mutate(weight = as.factor(weight2)) |&gt;\n  select(-weight2))\n\ncasein_final \n\n# A tibble: 71 × 2\n   feed  weight\n   &lt;fct&gt; &lt;fct&gt; \n 1 other LOW   \n 2 other LOW   \n 3 other LOW   \n 4 other LOW   \n 5 other LOW   \n 6 other LOW   \n 7 other LOW   \n 8 other LOW   \n 9 other LOW   \n10 other LOW   \n# ℹ 61 more rows\n\n\nNote: The variable “feed” has two levels, other and casein, while the variable “weight” has two levels, high and low.\nNext, I can start the analysis…"
  },
  {
    "objectID": "miniproject2.html#observed-difference",
    "href": "miniproject2.html#observed-difference",
    "title": "Mini Project 2",
    "section": "",
    "text": "First, I wrote a code to calculate the observed difference between the proportion of higher weight chicks between groups for the treatment (casein) and control (other) groups.\n\ncasein_summary &lt;- casein_final |&gt;\n group_by(feed) |&gt;\n  summarise(prop_high = mean (weight==\"HIGH\"))\nobserved_diff_cas &lt;- casein_summary [[2]][1] -casein_summary[[2]][2]\ncasein_summary\n\n# A tibble: 2 × 2\n  feed   prop_high\n  &lt;fct&gt;      &lt;dbl&gt;\n1 casein     0.75 \n2 other      0.390\n\nobserved_diff_cas \n\n[1] 0.3601695\n\n\nIt is also interesting to note that we can turn the above code into a function. For simple randomized studies, specifically those with a treatment variable consisting of two levels and a categorical two level outcome, we can create a function that calculates the observed difference and shows the observed proportions of the outcome.\n\ncreate_summary_obsdiff &lt;- function(data, treatment, outcome, prop) {\n  sum &lt;- data |&gt;\n group_by({{treatment}}) |&gt;\n  summarise(prop_yes = mean ({{outcome}}== prop))\n  observed_diff &lt;- sum [[2]][1] -sum[[2]][2]\nprint(sum)\nobserved_diff \n  } \n\ncreate_summary_obsdiff(casein_final, feed, weight, \"HIGH\")\n\n# A tibble: 2 × 2\n  feed   prop_yes\n  &lt;fct&gt;     &lt;dbl&gt;\n1 casein    0.75 \n2 other     0.390\n\n\n[1] 0.3601695\n\n\nWe could do this with the dolphin data set that we were working with in class where the data would be dolphin data, the treatment would be treatment with levels Dolphin and Control, the outcome would be improve with levels yes and no, and the prop would be “Yes”. Outcome refers to the response variable you will be examining and prop refers to what you will be calculating the proportion of within that outcome. Usually we look at positive improvements or the presence of something, so I named this variable prop_yes.\nExample with Dolphin Data\n\ndolphin_data &lt;- tibble(treatment = rep(c(\"Dolphin\", \"Control\"), each = 15),\n                       improve = c(rep(\"Yes\", 10), rep(\"No\", 5), \n                                   rep(\"Yes\", 3), rep(\"No\", 12)))\n\ncreate_summary_obsdiff(dolphin_data, treatment, improve, \"Yes\")\n\n# A tibble: 2 × 2\n  treatment prop_yes\n  &lt;chr&gt;        &lt;dbl&gt;\n1 Control      0.2  \n2 Dolphin      0.667\n\n\n[1] -0.4666667"
  },
  {
    "objectID": "miniproject2.html#create-the-null-world",
    "href": "miniproject2.html#create-the-null-world",
    "title": "Mini Project 2",
    "section": "",
    "text": "Next, we will create a null world that shuffles the feed or treatment among the chicks. We can calculate the simulated difference, which is the difference in proportion of higher weight chicks if there was no dependence on feed.\n\nsimulated_diff_cas &lt;- vector(\"double\", 1000)\nfor(i in 1:1000) {\n  casein_summary1 &lt;- casein_final |&gt;\n  mutate(shuffled_treatment = sample(feed)) |&gt;\n  group_by(shuffled_treatment) |&gt;\n  summarize(prop_yes = mean (weight==\"HIGH\"))\nsimulated_diff_cas[[i]] &lt;- casein_summary1[[2]][1]-casein_summary1[[2]][2]\n}"
  },
  {
    "objectID": "miniproject2.html#plot",
    "href": "miniproject2.html#plot",
    "title": "Mini Project 2",
    "section": "",
    "text": "Finally we can use these simulated differences to calculate how rare getting our observed difference would be.\n\nnull_world_cas &lt;- tibble(simulated_diff_cas = simulated_diff_cas)\nggplot(null_world_cas, aes(x=simulated_diff_cas)) +\n  geom_histogram(bins= 25, fill= \"darkseagreen1\")+\n  geom_vline(xintercept= observed_diff_cas, color= \"hotpink\") +\n  theme_classic() + \n  labs(x= \"Simulated Difference Between Feed types\", y= \"Count\",\n       title= \"Simulation of the Difference in the Proportion of Higher Weight Chicks \nfed with Casein feed and Other Types of Feed in the Null World\", subtitle= \"With a Line Representing the the Observed Difference\", \ncaption=\"Source: Anonymous (1948) Biometrika, 35, 214\")\n\n\n\n\nLooking at the above plot, we can see our simulated null world approximately follows the normal curve, with the mean around zero. This would make sense if there is no difference in types of feed in this simulation because the average weight should be about the same for both groups. Assuming the casein feed has no affect on chick weights, the bulk of the simulated differences lie between -0.25 and 0.25. The pink line represents our observed difference, which is possible to obtain if casein has no affect on chick weight, but it is more unlikely.\n\np_value &lt;- sum(simulated_diff_cas&gt;=observed_diff_cas)/1000\np_value\n\n[1] 0.027\n\n\nWe can also calculate the p-value which is shown above. The p-value represents the chance that we would get an observed difference that is equal to or above the difference that we got. Because our p-value is less than 0.05, we can reject the null hypothesis that casein feed has no effect on chick weights compared to other types of feed."
  },
  {
    "objectID": "miniproject2.html#further-study",
    "href": "miniproject2.html#further-study",
    "title": "Mini Project 2",
    "section": "",
    "text": "The p-value can also be analyzed by a two sided test, instead of a one sided test. This would take into account the probability of getting the negative of our observed difference and lower. This would raise our p-value. It would be interesting to study chicks with a more consistent control group like the most common type of feed, instead of random feeds lumped together. It would also be interesting to pair this with an analysis of average chick weights at certain points in life in order to get a better understanding of a higher and lower weight chick. The data would also be more accurate with a larger sample size."
  },
  {
    "objectID": "miniproject3.html",
    "href": "miniproject3.html",
    "title": "Mini Project 3",
    "section": "",
    "text": "Complexions in Makeup Products\nI got my data from The Pudding Essay “The Naked Truth”. (Source: https://pudding.cool/2021/03/foundation-names/)\nI wanted to examine the proportion of foundation products for fair skin and deep skin, so I created a dataset that shows the products that included “fair”, “deep”, and similar words in their description. I calculated the proportion of shades for fair skin and dark skin for each product.\n\ncomplex &lt;- sephora |&gt;\n  select(brand, description, product, name, specific)|&gt;\n  mutate(fair = \n           ifelse((str_detect(description, \"[Ff]air\")|str_detect(description, \"\\\\b[Ll]ight\")|str_detect(description, \"[Mm]edium\") |str_detect(description, \"[Pp]ale\")), 1, 0), \n         deep = ifelse((str_detect(description, \"[Dd]eep\")|str_detect(description, \"[Tt]an\")|str_detect(description, \"[Rr]ich\")|str_detect(description, \"[Dd]ark\")), \n                       1, 0)) |&gt;\n  group_by(product)|&gt;\n  summarise(prop_fair= mean(fair), prop_deep= mean(deep))|&gt;\n  filter(str_detect(prop_fair, \"0\\\\.\\\\d*\"), str_detect(prop_deep, \"0\\\\.\\\\d*\")) |&gt;\n arrange(desc(prop_fair))\n\ncomplex\n\n# A tibble: 158 × 3\n   product                                                   prop_fair prop_deep\n   &lt;chr&gt;                                                         &lt;dbl&gt;     &lt;dbl&gt;\n 1 Silk Crème Moisturizing Photo Edition Foundation              0.938    0.25  \n 2 Silk Crème Oil Free Photo Edition Foundation                  0.938    0.25  \n 3 Matissime Velvet Radiant Mattifying Fluid Foundation SPF…     0.917    0.417 \n 4 The Luminous Lifting Cushion Foundation SPF 20 + Refill       0.917    0.0833\n 5 Immaculate® Liquid Powder Foundation Mattifying Oil Free      0.909    0.273 \n 6 Vanish™ Seamless Finish Foundation Stick                      0.906    0.344 \n 7 Vanish™ Seamless Finish Liquid Foundation                     0.906    0.344 \n 8 Diorskin Forever Undercover Foundation                        0.9      0.25  \n 9 Pure Radiant Tinted Moisturizer Broad Spectrum SPF 30         0.9      0.4   \n10 Teint Couture Everwear 24H Foundation SPF 20                  0.9      0.367 \n# ℹ 148 more rows\n\n\nNext I took ten products with the most fair shades and graphed it with its proportion of deep shades. I did the same with the ten products with the least amount of fair shades.\n\ncomplex |&gt;\n  head(10) |&gt; \n  pivot_longer(-product, names_to= \"complex\", values_to= \"value\") |&gt;\n  ggplot(aes(x=value, y=product, fill= complex))+\n  geom_col() +\n  labs(x= \"Proportion\", y= \"Product\", fill= \"Complexion\", title= \"The Proportion of Fair Skin Shades \nand Deep Skin Shades for Products with \nmostly Fair Skin Products\")\n\n\n\n\n\ncomplex |&gt;\n  tail(10) |&gt;\n pivot_longer(-product, names_to= \"complex\", values_to= \"value\") |&gt;\n  ggplot(aes(x=value, y=product, fill= complex))+\n  geom_col()+\n  labs(x= \"Proportion\", y= \"Product\", fill= \"Complexion\", title= \"The Proportion of Fair Skin \nShades and Deep Skin \nShades for Products with \nmore Deep Skin Products\")\n\n\n\n\nAs you can see from the above graphs, the ten products with the most fair shades had really low percentages of deep shades compared to the proportion of fair shades for the ten products with the most deep shades. The products with the most deep shades sometimes even had more fair shades or about the same number of fair shades. (Some shades can be used for multiple skin tones as well, which is why the proportions don’t add up to one). This suggests some disparity between the available deep shades and fair shades for a lot of foundations. Fair shades appear to be more readily available\nI then wanted to see what words in the descriptions of these shades had capital letters. Capital letters typically correspond to a place, food, or material that represents the shade.\n\nstr_view(sephora$description, \"[A-Z][A-Za-z]+\\\\b\")\n\n [30] │ 340 for tan skin with cool undertones (&lt;Rihanna&gt;'s &lt;Shade&gt;) - &lt;Selected&gt;\n [93] │ 445 for deep skin with warm olive undertones - &lt;Selected&gt;\n[125] │ 7.8 tan, olive - &lt;Selected&gt;\n[155] │ 1 &lt;Rendevous&gt; very fair with cool undertones\n[156] │ 2 &lt;Tulum&gt; very fair with warm undertones\n[157] │ 3 &lt;Balos&gt; &lt;Fair&gt; with neutral cool undertones\n[158] │ 4 &lt;Formosa&gt; fair with warm undertones\n[159] │ 5 &lt;Bom&gt; &lt;Bom&gt; light with neutral undertones\n[160] │ 6 &lt;Ora&gt; light with warm undertones\n[161] │ 7 &lt;Diaz&gt; &lt;Light&gt; medium with neutral undertones\n[162] │ 8 &lt;Shela&gt; &lt;Light&gt; medium with neutral warm undertones\n[163] │ 9 &lt;Paloma&gt; medium with neutral undertones\n[164] │ 10 &lt;Porto&gt; &lt;Ferro&gt; medium with warm undertones\n[165] │ 11 &lt;Matira&gt; medium tan with neutral undertones\n[166] │ 12 &lt;Kokkini&gt; medium tan with warm undertones - &lt;Selected&gt;\n[167] │ 13 &lt;Kamari&gt; medium dark with warm undertones\n[168] │ 14 &lt;Dominica&gt; medium dark with neutral undertones\n[169] │ 15 &lt;Porto&gt; &lt;Covo&gt; &lt;Dark&gt; with neutral undertones\n[170] │ 16 &lt;Pavones&gt; dark with warm undertones\n[171] │ 17 &lt;Miho&gt; &lt;Deep&gt; with warm undertones\n... and 3309 more\n\n\nI then wanted to compare these capital words (it would only be the first capital for each shade if there are multiple). To see what relationship there might be between shade names and descriptor words.\n\nsephora |&gt; \n  select(brand, description, product, name, specific)|&gt;\n  mutate(fair = \n           ifelse((str_detect(description, \"[Ff]air\")|str_detect(description, \"\\\\b[Ll]ight\")|str_detect(description, \"[Mm]edium\") |str_detect(description, \"[Pp]ale\")), 1, 0), \n         deep = ifelse((str_detect(description, \"[Dd]eep\")|str_detect(description, \"[Tt]an\")|str_detect(description, \"[Rr]ich\")|str_detect(description, \"[Dd]ark\")), \n                       1, 0)) |&gt;\n  mutate(capital = str_extract(description, \"[A-Z][a-z]+\\\\b\")) |&gt;\n  drop_na()|&gt;\n  group_by(capital)|&gt;\n  summarise(prop_fair= mean(fair), prop_deep= mean(deep))|&gt;\n  filter(str_detect(prop_fair, \"0\\\\.\\\\d*\"), str_detect(prop_deep, \"0\\\\.\\\\d*\")) |&gt;\n arrange(desc(prop_fair)) |&gt;\n  print(n=Inf)\n\n# A tibble: 42 × 3\n   capital    prop_fair prop_deep\n   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n 1 Light         0.972     0.0183\n 2 Shell         0.889     0.111 \n 3 Soft          0.889     0.111 \n 4 Vanilla       0.875     0.125 \n 5 Natural       0.846     0.231 \n 6 Bisque        0.842     0.342 \n 7 Dune          0.833     0.333 \n 8 Selected      0.75      0.375 \n 9 Beige         0.7       0.1   \n10 Sand          0.667     0.0833\n11 Tea           0.667     0.333 \n12 Golden        0.655     0.436 \n13 Honey         0.643     0.286 \n14 Surreal       0.643     0.214 \n15 Chai          0.6       0.6   \n16 Fawn          0.6       0.6   \n17 Cool          0.508     0.305 \n18 Bamboo        0.5       0.5   \n19 Cardamom      0.5       0.5   \n20 Ginger        0.5       0.5   \n21 Hazel         0.5       0.5   \n22 Porto         0.5       0.5   \n23 Sandalwood    0.5       0.5   \n24 Sepia         0.5       0.5   \n25 Tawny         0.5       0.5   \n26 Teak          0.5       0.5   \n27 Toffee        0.5       0.5   \n28 Warm          0.453     0.344 \n29 Neutral       0.444     0.363 \n30 Latte         0.4       0.6   \n31 Peach         0.4       0.2   \n32 Oak           0.333     0.667 \n33 Tone          0.312     0.562 \n34 Almond        0.25      0.75  \n35 Desert        0.25      0.5   \n36 Sable         0.25      0.75  \n37 Walnut        0.222     0.667 \n38 Chestnut      0.2       0.8   \n39 Nutmeg        0.2       0.6   \n40 Maple         0.167     0.667 \n41 Suede         0.103     0.759 \n42 Mocha         0.0909    0.636 \n\n\nSurprisingly, some of the words seem to have an even split between deep and fair shades. Although there are obviously some that have more fair shades (Vanilla), and more deep shades (Mocha). One I find particularly interesting is that Natural has more fair shades than deep shades. Is this inadvertently implying that deeper skin tones are not natural and fair skin tones are? This implies that there are some past racial biases that still exist in today’s culture.\nOne word I wanted to look at specifically is nude. Similar to natural, nude is technically anyone’s natural skin tone, but I wanted to see if it was present more on fair shade foundations.\n\nnude &lt;- sephora |&gt; \n  select(brand, description, product, name, specific)|&gt;\n  mutate(fair = \n           ifelse((str_detect(description, \"[Ff]air\")|str_detect(description, \"\\\\b[Ll]ight\")|str_detect(description, \"[Mm]edium\") |str_detect(description, \"[Pp]ale\")), 1, 0), \n         deep = ifelse((str_detect(description, \"[Dd]eep\")|str_detect(description, \"[Tt]an\")|str_detect(description, \"[Rr]ich\")|str_detect(description, \"[Dd]ark\")), \n                       1, 0)) |&gt;\n  mutate(nude = str_extract(description, \"[Nn]ude\")) |&gt;\n  drop_na()|&gt;\n  group_by(nude)|&gt;\n  summarise(prop_fair= mean(fair), prop_deep= mean(deep))|&gt;\n  pivot_longer(!nude, names_to = \"complex\", values_to= \"value\")\n\n\nnude |&gt;\n  ggplot(aes(x= complex, y= value)) +\n  geom_col(fill= \"hotpink2\") +\n  labs(x= \"Complexion\", y= \"Proportion\", title= \"Proportion of Products that Mention Nude for Fair and Deep Complexions\")\n\n\n\n\nA lot of deep shades have nude in their descriptor, as well as a lot of fair shades. There are many more fair shades that contain the word, although it’s not like the deeper shades are lacking in that descriptor.\nOverall, this data could imply the presence of some racial biases, but it is not nearly as bad as I thought it would be."
  },
  {
    "objectID": "miniproject.html",
    "href": "miniproject.html",
    "title": "Mini Project 1",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nMaps: Wisconsin Parties in 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaps: US States Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "miniproject/maps2/index.html",
    "href": "miniproject/maps2/index.html",
    "title": "Maps: Wisconsin Parties in 2016",
    "section": "",
    "text": "I followed the same process we did for the North Carolina data. I downloaded the UCLA data. The code below uses the data set made from a fec16 package that filters for Wisconsin results only. Next, we can draw the districts for Wisconsin.\n\nwi_shp &lt;- districts |&gt;\n  filter(STATENAME == \"Wisconsin\")\nwi_shp |&gt;\n  st_geometry() |&gt;\n  plot(col = gray.colors(nrow(wi_shp)))\n\n\n\n\n\nwi_merged &lt;- wi_shp |&gt;\n  st_transform(4326) |&gt;\n  inner_join(wi_results, by = c(\"DISTRICT\" = \"district\"))\nhead(wi_merged, width = Inf)\n\nWe can now show the results for the 2016 election and show which party one which district and the level of Democratic and Republican support for each.\n\nwi &lt;- ggplot(data = wi_merged, aes(fill = winner)) +\n  annotation_map_tile(zoom = 6, type = \"osm\", progress = \"none\") + \n  geom_sf(alpha = 0.5) +\n  scale_fill_manual(\"Winner\", values = c(\"blue\", \"red\")) + \n  geom_sf_label(aes(label = DISTRICT), fill = \"white\") + \n  theme_void()\nwi\n\n\n\n\n\nwi +\n  aes(fill = r_prop) + \n  scale_fill_distiller(\n    \"Proportion\\nRepublican\", \n    palette = \"RdBu\", \n    limits = c(0.0, 0.7)\n  ) +\n  labs(title= \"Levels of Democratic and Republican Support \nby District in Wisconsin in 2016\")\n\n\n\n\nThis map shows the voting breakdown for Wisconsin in 2016. Most of the districts in Wisconsin are majority republican. Two districts are completely democratic though, with a third district being less democratic but still democratic."
  }
]